{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/SolarPrediction.csv'  # Update this path if necessary\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = data[['Temperature', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed']].values\n",
        "y = data['Radiation'].values\n",
        "\n",
        "# Handle any missing values (if any)\n",
        "X = np.nan_to_num(X)\n",
        "y = np.nan_to_num(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Baseline Model: Linear Regression\n",
        "baseline_model = LinearRegression()\n",
        "baseline_model.fit(X_train, y_train)\n",
        "y_pred_baseline = baseline_model.predict(X_test)\n",
        "baseline_mse = mean_squared_error(y_test, y_pred_baseline)\n",
        "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
        "print(f'Baseline Linear Regression MSE: {baseline_mse}')\n",
        "print(f'Baseline Linear Regression R²: {baseline_r2}')\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Predict and evaluate the model on the test data\n",
        "y_pred_nn = model.predict(X_test)\n",
        "nn_mse = mean_squared_error(y_test, y_pred_nn)\n",
        "nn_r2 = r2_score(y_test, y_pred_nn)\n",
        "print(f'Neural Network MSE: {nn_mse}')\n",
        "print(f'Neural Network R²: {nn_r2}')\n",
        "\n",
        "# Compare the performance\n",
        "print(f'Baseline Linear Regression MSE: {baseline_mse}')\n",
        "print(f'Baseline Linear Regression R²: {baseline_r2}')\n",
        "print(f'Neural Network MSE: {nn_mse}')\n",
        "print(f'Neural Network R²: {nn_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVknlaFON6ff",
        "outputId": "081865b1-f9ed-4061-bcf2-150e8421df72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Linear Regression MSE: 43911.783476563374\n",
            "Baseline Linear Regression R²: 0.5579949826470867\n",
            "Epoch 1/50\n",
            "654/654 [==============================] - 2s 2ms/step - loss: 76957.6328 - val_loss: 40838.6758\n",
            "Epoch 2/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 37277.2305 - val_loss: 37449.7812\n",
            "Epoch 3/50\n",
            "654/654 [==============================] - 2s 2ms/step - loss: 35382.2266 - val_loss: 36275.4766\n",
            "Epoch 4/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 34339.8242 - val_loss: 35528.5586\n",
            "Epoch 5/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 33649.7227 - val_loss: 34926.1328\n",
            "Epoch 6/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 33266.8086 - val_loss: 34642.5039\n",
            "Epoch 7/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 32989.2031 - val_loss: 34364.3047\n",
            "Epoch 8/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 32765.5273 - val_loss: 34213.9609\n",
            "Epoch 9/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 32630.0469 - val_loss: 34136.5977\n",
            "Epoch 10/50\n",
            "654/654 [==============================] - 2s 4ms/step - loss: 32492.2715 - val_loss: 34353.9375\n",
            "Epoch 11/50\n",
            "654/654 [==============================] - 3s 5ms/step - loss: 32421.9355 - val_loss: 33877.9062\n",
            "Epoch 12/50\n",
            "654/654 [==============================] - 4s 5ms/step - loss: 32304.6230 - val_loss: 33850.8164\n",
            "Epoch 13/50\n",
            "654/654 [==============================] - 3s 4ms/step - loss: 32249.8418 - val_loss: 33765.4453\n",
            "Epoch 14/50\n",
            "654/654 [==============================] - 3s 5ms/step - loss: 32163.6133 - val_loss: 33737.0781\n",
            "Epoch 15/50\n",
            "654/654 [==============================] - 3s 4ms/step - loss: 32136.7871 - val_loss: 33680.6406\n",
            "Epoch 16/50\n",
            "654/654 [==============================] - 3s 5ms/step - loss: 32052.6953 - val_loss: 33681.3477\n",
            "Epoch 17/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 31982.0371 - val_loss: 33616.9062\n",
            "Epoch 18/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31970.3164 - val_loss: 33538.7461\n",
            "Epoch 19/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31860.8105 - val_loss: 33722.1211\n",
            "Epoch 20/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31838.8711 - val_loss: 33624.6250\n",
            "Epoch 21/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31833.3359 - val_loss: 33429.0586\n",
            "Epoch 22/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31775.1523 - val_loss: 33675.5547\n",
            "Epoch 23/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31749.2383 - val_loss: 33678.6055\n",
            "Epoch 24/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31714.9980 - val_loss: 33320.7539\n",
            "Epoch 25/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 31648.3203 - val_loss: 33366.7227\n",
            "Epoch 26/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 31617.4199 - val_loss: 33358.3438\n",
            "Epoch 27/50\n",
            "654/654 [==============================] - 2s 2ms/step - loss: 31585.5078 - val_loss: 33296.0898\n",
            "Epoch 28/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31580.5488 - val_loss: 33198.9492\n",
            "Epoch 29/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31528.6562 - val_loss: 33227.6602\n",
            "Epoch 30/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31499.0059 - val_loss: 33134.0430\n",
            "Epoch 31/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31444.7676 - val_loss: 33120.8008\n",
            "Epoch 32/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31387.9648 - val_loss: 33165.5664\n",
            "Epoch 33/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31373.2422 - val_loss: 32989.8984\n",
            "Epoch 34/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31338.3047 - val_loss: 33157.5703\n",
            "Epoch 35/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 31303.1738 - val_loss: 32985.2383\n",
            "Epoch 36/50\n",
            "654/654 [==============================] - 2s 2ms/step - loss: 31262.1250 - val_loss: 33017.2031\n",
            "Epoch 37/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31194.9707 - val_loss: 33065.7070\n",
            "Epoch 38/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31186.8828 - val_loss: 32898.5977\n",
            "Epoch 39/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31156.3281 - val_loss: 32820.4219\n",
            "Epoch 40/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31080.9180 - val_loss: 32848.0781\n",
            "Epoch 41/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 31026.8105 - val_loss: 33074.7891\n",
            "Epoch 42/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30992.6738 - val_loss: 32798.4297\n",
            "Epoch 43/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30961.8555 - val_loss: 32685.1367\n",
            "Epoch 44/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 30953.8086 - val_loss: 32619.8145\n",
            "Epoch 45/50\n",
            "654/654 [==============================] - 2s 3ms/step - loss: 30908.6523 - val_loss: 32610.0918\n",
            "Epoch 46/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30861.1875 - val_loss: 32564.2227\n",
            "Epoch 47/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30856.6914 - val_loss: 32510.0723\n",
            "Epoch 48/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30815.5879 - val_loss: 32586.4863\n",
            "Epoch 49/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30766.3027 - val_loss: 32479.0117\n",
            "Epoch 50/50\n",
            "654/654 [==============================] - 1s 2ms/step - loss: 30759.4707 - val_loss: 32432.2930\n",
            "205/205 [==============================] - 0s 1ms/step\n",
            "Neural Network MSE: 30763.0086574755\n",
            "Neural Network R²: 0.6903472576391143\n",
            "Baseline Linear Regression MSE: 43911.783476563374\n",
            "Baseline Linear Regression R²: 0.5579949826470867\n",
            "Neural Network MSE: 30763.0086574755\n",
            "Neural Network R²: 0.6903472576391143\n"
          ]
        }
      ]
    }
  ]
}